{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d332e35",
   "metadata": {},
   "source": [
    "#### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1916cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from tqdm.auto import tqdm\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabdl import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6573346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b986dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c8658",
   "metadata": {},
   "source": [
    "#### Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1532ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, dataloader, loss_fn, device, task_type):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in dataloader:\n",
    "        if len(batch) == 3:\n",
    "            x_cont, x_cat, y = batch\n",
    "            x_cont, x_cat, y = x_cont.to(device), x_cat.to(device), y.to(device)\n",
    "        if len(batch) == 2:\n",
    "            x_cont, y = batch\n",
    "            x_cont, y = x_cont.to(device), y.to(device)\n",
    "            x_cat = None\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_cont, x_cat)\n",
    "        if task_type == 'regression':\n",
    "            preds = preds.flatten()\n",
    "        loss = loss_fn(preds, y)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, metric_func, task_type):\n",
    "    model.eval()\n",
    "    preds_all = []\n",
    "    y_all = []\n",
    "    for batch in dataloader:\n",
    "        if len(batch) == 3:\n",
    "            x_cont, x_cat, y = batch\n",
    "            x_cont, x_cat, y = x_cont.to(device), x_cat.to(device), y.to(device)\n",
    "        if len(batch) == 2:\n",
    "            x_cont, y = batch\n",
    "            x_cont, y = x_cont.to(device), y.to(device)\n",
    "            x_cat = None\n",
    "        preds = model(x_cont, x_cat)\n",
    "        if task_type == 'regression':\n",
    "            preds = preds.flatten()\n",
    "        preds_all.append(preds.cpu().detach())\n",
    "        y_all.append(y.cpu().detach())\n",
    "    preds_all = torch.cat(preds_all)\n",
    "    if task_type == 'classification':\n",
    "        preds_all = preds_all.argmax(dim=1)\n",
    "    preds_all = preds_all.numpy()\n",
    "    y_all = torch.cat(y_all).numpy()\n",
    "    return metric_func(y_all, preds_all)\n",
    "\n",
    "\n",
    "def run_experiment(model, optimizer, dataloaders, loss_fn, device, metric_func, \n",
    "                   task_type, n_epoches, maximize=True, y_std=None):\n",
    "    best_val = None\n",
    "    best_test = None\n",
    "    best_step = None\n",
    "    for i in (pbar := tqdm(range(1, n_epoches + 1))):\n",
    "        loss = train_step(model, optimizer, dataloaders['train'], loss_fn, device, task_type)\n",
    "        metric_val = evaluate(model, dataloaders['val'], device, metric_func, task_type)\n",
    "        metric_test = evaluate(model, dataloaders['test'], device, metric_func, task_type)\n",
    "        str_desc = f'Loss: {loss}, val metric {metric_val}, test metric {metric_test}'\n",
    "        pbar.set_description(str_desc)\n",
    "        if best_val is None or (maximize and metric_val > best_val) or (not maximize and metric_val < best_val):\n",
    "            best_val = metric_val\n",
    "            best_test = metric_test\n",
    "            best_step = i\n",
    "    if task_type == 'regression' and y_std:\n",
    "        best_val *= y_std\n",
    "        best_test *= y_std\n",
    "    return {\n",
    "        'model': model.cpu(),\n",
    "        'val': best_val,\n",
    "        'test': best_test,\n",
    "        'best_step': best_step\n",
    "    }\n",
    "\n",
    "def experiments_series(experiment_name, model_class, model_args, model_kwargs,\n",
    "                       optimizer_class, learning_rate,\n",
    "                       dataloaders, loss_fn, device, metric_func, \n",
    "                       task_type, n_epoches, maximize, n_runs):\n",
    "    print(f'===== Running experiment \"{experiment_name}\" =====')\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    for _ in tqdm(range(n_runs)):\n",
    "        model = model_class(*model_args, **model_kwargs)\n",
    "        optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "        results = run_experiment(model, optimizer, dataloaders, loss_fn, device, metric_func,\n",
    "                                task_type, n_epoches, maximize)\n",
    "        val_results.append(results['val'])\n",
    "        test_results.append(results['test'])\n",
    "    val_results = np.array(val_results)\n",
    "    test_results = np.array(test_results)\n",
    "    \n",
    "    print('===== Experiments results =====')\n",
    "    print(f'Validation metric: {val_results.mean()}±{val_results.std()}')\n",
    "    print(f'Corresponding test metric: {test_results.mean()}±{test_results.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a984d",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4064176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTabDLModel(nn.Module):\n",
    "    def __init__(self, n_cont_features, cat_cardinalities, mlp_kwargs, model_type):\n",
    "        super().__init__()\n",
    "        self.cat_cardinalities = cat_cardinalities\n",
    "        d_cat = sum(cat_cardinalities)\n",
    "\n",
    "        \n",
    "        if model_type == 'MLP-PLR':\n",
    "            d_embedding = 24\n",
    "            self.cont_embeddings = layers.PeriodicEmbeddings(n_cont_features, d_embedding, lite=False)\n",
    "            d_num = n_cont_features * d_embedding\n",
    "        elif model_type == 'MLP':\n",
    "            self.cont_embeddings = nn.Identity()\n",
    "            d_num = n_cont_features\n",
    "        \n",
    "        self.backbone = layers.MLP(d_in=d_num + d_cat, **mlp_kwargs)\n",
    "\n",
    "    def forward(self, x_cont, x_cat):\n",
    "        x = []\n",
    "        x.append(self.cont_embeddings(x_cont).flatten(1))\n",
    "        if x_cat is not None:\n",
    "            x.extend(\n",
    "                F.one_hot(column, cardinality)\n",
    "                for column, cardinality in zip(x_cat.T, self.cat_cardinalities)\n",
    "            )\n",
    "        x = torch.column_stack(x)\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c73f1e",
   "metadata": {},
   "source": [
    "#### Experiment: regression on California Housing dataset\n",
    "\n",
    "There is no categorical features. Let's prepare data. First of all we will read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7f77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.fetch_california_housing()\n",
    "X_cont = dataset[\"data\"]\n",
    "Y = dataset[\"target\"]\n",
    "X_cont = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "Y = Y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46bc3f7",
   "metadata": {},
   "source": [
    "Now let's make train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18557d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_idx = np.arange(len(Y))\n",
    "trainval_idx, test_idx = sklearn.model_selection.train_test_split(\n",
    "    all_idx, train_size=0.8, random_state=42\n",
    ")\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
    "    trainval_idx, train_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "X_train, y_train = X_cont[train_idx], Y[train_idx]\n",
    "X_val, y_val = X_cont[val_idx], Y[val_idx]\n",
    "X_test, y_test = X_cont[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffb9f3",
   "metadata": {},
   "source": [
    "We will use quantile tranform with noise to obtain initial embeddings for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30cc7360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuantileTransformer(n_quantiles=440, output_distribution=&#x27;normal&#x27;,\n",
       "                    subsample=1000000000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(n_quantiles=440, output_distribution=&#x27;normal&#x27;,\n",
       "                    subsample=1000000000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "QuantileTransformer(n_quantiles=440, output_distribution='normal',\n",
       "                    subsample=1000000000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.default_rng(42).normal(0.0, 1e-5, X_train.shape).astype(X_train.dtype)\n",
    "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
    "    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n",
    "    output_distribution=\"normal\",\n",
    "    subsample=10**9,\n",
    ")\n",
    "preprocessing.fit(X_train + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d52acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.transform(X_train)\n",
    "X_val = preprocessing.transform(X_val)\n",
    "X_test = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aff4af",
   "metadata": {},
   "source": [
    "Also let's normalize target, it will make training process more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1688ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean, y_std = y_train.mean(), y_train.std()\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "y_val = (y_val - y_mean) / y_std\n",
    "y_test = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a8709",
   "metadata": {},
   "source": [
    "And now we can make dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "238f94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = data.TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "dataloader_train = data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataset_val = data.TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "dataloader_val = data.DataLoader(\n",
    "    dataset=dataset_val,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataset_test = data.TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "dataloader_test = data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3cc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': dataloader_train,\n",
    "    'val': dataloader_val,\n",
    "    'test': dataloader_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900cee7",
   "metadata": {},
   "source": [
    "That's all! Let's run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running experiment \"Simple MLP on California Housing data\" =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70e6c940fa74b32b012f48c9f75bbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f6b0ffe324f3fb53b5b0180381d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f83fed801047459057ad31488b30bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb188f3ea554e979d5f27a97535d0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c9d9f0e70c474a8ec8e46ee3fe3ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe732cc6903141f2b9ca4f9df33541ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d46151df50d48b0a77384639bf5b128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90ba2b1530b48c4a23ab02043d749c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c260dc5b7514a19a486cf3fef6d0533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a19282a8a7455fa1f0ea11422b967e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e379b1cbbe34ef395c0a87bd2bd683d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Experiments results =====\n",
      "Validation metric: 0.47289156913757324±0.002077018842101097\n",
      "Corresponding test metric: 0.4653613567352295±0.001773171010427177\n"
     ]
    }
   ],
   "source": [
    "experiments_series(\n",
    "    experiment_name='Simple MLP on California Housing data',\n",
    "    model_class=BasicTabDLModel,\n",
    "    model_args=[],\n",
    "    model_kwargs={\n",
    "        'n_cont_features': n_cont_features,\n",
    "        'cat_cardinalities': [], \n",
    "        'mlp_kwargs':     {\n",
    "                            \"d_layers\": [384, 384],\n",
    "                            \"dropouts\": [0.4, 0.4],\n",
    "                            \"activation\": nn.ReLU,\n",
    "                            \"d_out\": 1,\n",
    "                          },\n",
    "        'model_type': 'MLP'\n",
    "    },\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    learning_rate=3e-4,\n",
    "    dataloaders=dataloaders,\n",
    "    loss_fn=F.mse_loss,\n",
    "    device=device,\n",
    "    metric_func=functools.partial(sklearn.metrics.mean_squared_error, squared=False),\n",
    "    task_type='regression',\n",
    "    n_epoches=100,\n",
    "    maximize=False,\n",
    "    n_runs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd973730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running experiment \"MLP-PLR on California Housing data\" =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f720afe1213041d790d628118be08c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad7c3e800664b99a53ebb554c97d82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7989ddd2c14c739eeab0644ec03945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb71bfa86ee144e2adeb5775e5715956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510715ae07d34533aa28e48368532be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2a95429af74b8a9b275cc42ccb0aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1b31a741884065ba08c94a8c94c6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54777c4c39a444dcaeaedb63ea95cbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b190363bb24f59b67f8344f1743c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d9bf86167948e2b7a69ce8dff70f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea3bd99f026402d90888a316e0f635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Experiments results =====\n",
      "Validation metric: 0.4334487020969391±0.002482748357579112\n",
      "Corresponding test metric: 0.41462865471839905±0.0026303681079298258\n"
     ]
    }
   ],
   "source": [
    "experiments_series(\n",
    "    experiment_name='MLP-PLR on California Housing data',\n",
    "    model_class=BasicTabDLModel,\n",
    "    model_args=[],\n",
    "    model_kwargs={\n",
    "        'n_cont_features': n_cont_features,\n",
    "        'cat_cardinalities': [], \n",
    "        'mlp_kwargs':     {\n",
    "                            \"d_layers\": [384, 384],\n",
    "                            \"dropouts\": [0.4, 0.4],\n",
    "                            \"activation\": nn.ReLU,\n",
    "                            \"d_out\": 1,\n",
    "                          },\n",
    "        'model_type': 'MLP-PLR'\n",
    "    },\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    learning_rate=3e-4,\n",
    "    dataloaders=dataloaders,\n",
    "    loss_fn=F.mse_loss,\n",
    "    device=device,\n",
    "    metric_func=functools.partial(sklearn.metrics.mean_squared_error, squared=False),\n",
    "    task_type='regression',\n",
    "    n_epoches=100,\n",
    "    maximize=False,\n",
    "    n_runs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a8dfb",
   "metadata": {},
   "source": [
    "#### Experiment: multi-class classification on Covertype dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de093de2",
   "metadata": {},
   "source": [
    "First 10 columns are numerical, other are categorical (binary). Also we want to shift targets by one so that they start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1529544",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.fetch_covtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d844605",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont = dataset[\"data\"][:, :10]\n",
    "X_cat = dataset[\"data\"][:, 10:]\n",
    "Y = dataset[\"target\"]\n",
    "X_cont = X_cont.astype(np.float32)\n",
    "X_cat = X_cat.astype(np.int64)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "Y = Y.astype(np.int64) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7945a6d",
   "metadata": {},
   "source": [
    "Let's make split again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6916af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_idx = np.arange(len(Y))\n",
    "trainval_idx, test_idx = sklearn.model_selection.train_test_split(\n",
    "    all_idx, train_size=0.8, random_state=42\n",
    ")\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
    "    trainval_idx, train_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "X_cont_train, X_cat_train, y_train = X_cont[train_idx], X_cat[train_idx], Y[train_idx]\n",
    "X_cont_val, X_cat_val, y_val = X_cont[val_idx], X_cat[val_idx], Y[val_idx]\n",
    "X_cont_test, X_cat_test, y_test = X_cont[test_idx], X_cat[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0bdb8a",
   "metadata": {},
   "source": [
    "The same preprocessing as in California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb02d076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;, subsample=1000000000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;, subsample=1000000000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "QuantileTransformer(output_distribution='normal', subsample=1000000000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.default_rng(42).normal(0.0, 1e-5, X_cont_train.shape).astype(X_cont_train.dtype)\n",
    "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
    "    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n",
    "    output_distribution=\"normal\",\n",
    "    subsample=10**9,\n",
    ")\n",
    "preprocessing.fit(X_cont_train + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f315426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont_train = preprocessing.transform(X_cont_train)\n",
    "X_cont_val = preprocessing.transform(X_cont_val)\n",
    "X_cont_test = preprocessing.transform(X_cont_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f618f",
   "metadata": {},
   "source": [
    "Dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17d6e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = data.TensorDataset(torch.tensor(X_cont_train), torch.tensor(X_cat_train), torch.tensor(y_train))\n",
    "dataloader_train = data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataset_val = data.TensorDataset(torch.tensor(X_cont_val), torch.tensor(X_cat_val), torch.tensor(y_val))\n",
    "dataloader_val = data.DataLoader(\n",
    "    dataset=dataset_val,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataset_test = data.TensorDataset(torch.tensor(X_cont_test), torch.tensor(X_cat_test), torch.tensor(y_test))\n",
    "dataloader_test = data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2de9285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': dataloader_train,\n",
    "    'val': dataloader_val,\n",
    "    'test': dataloader_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388ee51",
   "metadata": {},
   "source": [
    "And experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30284d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running experiment \"Simple MLP on Covertype data\" =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe0d14194b848679a1486ba13b6e986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9603701a93b4955aff1149c0c8dcab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3bbfcd432e4a0ab5c75e37c79b7111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Experiments results =====\n",
      "Validation metric: 0.7713528108259289±0.0014468277360641935\n",
      "Corresponding test metric: 0.7698080083990947±0.001729731590406458\n"
     ]
    }
   ],
   "source": [
    "experiments_series(\n",
    "    experiment_name='Simple MLP on Covertype data',\n",
    "    model_class=BasicTabDLModel,\n",
    "    model_args=[],\n",
    "    model_kwargs={\n",
    "        'n_cont_features': n_cont_features,\n",
    "        'cat_cardinalities': 2 * np.ones(shape=X_cat_train.shape[1], dtype=int), \n",
    "        'mlp_kwargs':     {\n",
    "                            \"d_layers\": [384, 384],\n",
    "                            \"dropouts\": [0.4, 0.4],\n",
    "                            \"activation\": nn.ReLU,\n",
    "                            \"d_out\": 7,\n",
    "                          },\n",
    "        'model_type': 'MLP'\n",
    "    },\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    learning_rate=3e-4,\n",
    "    dataloaders=dataloaders,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    device=device,\n",
    "    metric_func=sklearn.metrics.accuracy_score,\n",
    "    task_type='classification',\n",
    "    n_epoches=2,\n",
    "    maximize=True,\n",
    "    n_runs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61aa54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running experiment \"MLP-PLR on Covertype data\" =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f608fa707e3140f196578b2fcc2635dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d672d128884346eea2869cf3492ca7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee085beab734234ad2301ece9e66938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Experiments results =====\n",
      "Validation metric: 0.795776769002388±0.0029044125556679234\n",
      "Corresponding test metric: 0.7949837783878213±0.002663442424033824\n"
     ]
    }
   ],
   "source": [
    "experiments_series(\n",
    "    experiment_name='MLP-PLR on Covertype data',\n",
    "    model_class=BasicTabDLModel,\n",
    "    model_args=[],\n",
    "    model_kwargs={\n",
    "        'n_cont_features': n_cont_features,\n",
    "        'cat_cardinalities': 2 * np.ones(shape=X_cat_train.shape[1], dtype=int), \n",
    "        'mlp_kwargs':     {\n",
    "                            \"d_layers\": [384, 384],\n",
    "                            \"dropouts\": [0.4, 0.4],\n",
    "                            \"activation\": nn.ReLU,\n",
    "                            \"d_out\": 7,\n",
    "                          },\n",
    "        'model_type': 'MLP-PLR'\n",
    "    },\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    learning_rate=3e-4,\n",
    "    dataloaders=dataloaders,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    device=device,\n",
    "    metric_func=sklearn.metrics.accuracy_score,\n",
    "    task_type='classification',\n",
    "    n_epoches=2,\n",
    "    maximize=True,\n",
    "    n_runs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b653346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
